{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and move BenthicNet data over to local node storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "move_script_path = \"./slurm/copy_and_extract_data.sh\"\n",
    "subprocess.run([\"bash\", move_script_path], check=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display system GPU resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    \"\"\"Get a list of available GPUs on the system.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        gpu_names = [torch.cuda.get_device_name(i) for i in range(num_gpus)]\n",
    "        return gpu_names\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "available_gpus = get_available_gpus()\n",
    "if available_gpus:\n",
    "    print(\"Available GPUs:\")\n",
    "    for i, gpu in enumerate(available_gpus):\n",
    "        print(f\"GPU {i + 1}: {gpu}\")\n",
    "else:\n",
    "    print(\"No GPUs available on the system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set arguments and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"rn50hl_one_hot_probe\"\n",
    "model = \"hl_rn50\"\n",
    "train_cfg_path = \"./cfgs/cnn/resnet50_hl.json\"\n",
    "model_checkpoint = f\"./pretrained_encoders/{model}.ckpt\"\n",
    "data_csv_path = \"/lustre06/project/6012565/isaacxu/benthicnet_probes/data_csv/one_hots/substrate_depth_2_data/substrate_depth_2_data.csv\"\n",
    "tar_dir = \"/lustre06/project/6012565/become_labelled/compiled_labelled_512px/tar\"\n",
    "\n",
    "one_hot = True\n",
    "random_partition = False\n",
    "\n",
    "seed = 42\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "max_epochs = 100\n",
    "dims = [2048]\n",
    "dropout = 0.7\n",
    "column = \"CATAMI Substrate\"\n",
    "\n",
    "nodes = 1\n",
    "gpus = len(available_gpus)\n",
    "\n",
    "test_mode = False\n",
    "fine_tune_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from utils.benthicnet_dataset import OneHotBenthicNetDataset, gen_datasets\n",
    "from utils.utils import construct_dataloaders, get_augs, get_df, set_seed\n",
    "\n",
    "\n",
    "def process_one_hot_df(data_df, col):\n",
    "    data_df[col] = data_df[col].apply(lambda x: ast.literal_eval(x)[0])\n",
    "    return data_df\n",
    "\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "data_df = process_one_hot_df(get_df(data_csv_path), column)\n",
    "num_classes = len(data_df[column].unique())\n",
    "dims.append(num_classes)\n",
    "\n",
    "train_cfg = {\n",
    "    \"backbone\": {\"name\": \"resnet50\", \"weights\": None, \"grad\": True},\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"max_epochs\": max_epochs,\n",
    "    \"dims\": dims,\n",
    "    \"dropout\": dropout,\n",
    "    \"backbone_params\": {\"zero_init_residual\": True},\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"adamw\",\n",
    "        \"lr\": 1e-5,\n",
    "        \"weight_decay\": 1e-05,\n",
    "        \"extra_optimizer_args\": {\"betas\": [0.9, 0.999]},\n",
    "    },\n",
    "    \"scheduler\": {\n",
    "        \"name\": \"warmup_cosine\",\n",
    "        \"interval\": \"epoch\",\n",
    "        \"warmup_epochs\": 10,\n",
    "        \"warmup_start_lr\": 1e-06,\n",
    "        \"min_lr\": 1e-06,\n",
    "    },\n",
    "}\n",
    "train_kwargs = OmegaConf.create(train_cfg)\n",
    "\n",
    "train_transform, val_transform = get_augs(colour_jitter=False)\n",
    "transform = [train_transform, val_transform]\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = gen_datasets(\n",
    "    data_df, tar_dir, transform, random_partition, one_hot=one_hot, seed=seed\n",
    ")\n",
    "\n",
    "dataloaders = construct_dataloaders(\n",
    "    [train_dataset, val_dataset, test_dataset], train_kwargs\n",
    ")\n",
    "\n",
    "train_dataloader = dataloaders[0]\n",
    "val_dataloader = dataloaders[1]\n",
    "test_dataloader = dataloaders[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import construct_one_hot_model\n",
    "\n",
    "# Build model\n",
    "model = construct_one_hot_model(\n",
    "    train_kwargs,\n",
    "    enc_pth=model_checkpoint,\n",
    "    test_mode=test_mode,\n",
    "    fine_tune_mode=fine_tune_mode,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up checkpointing and logging details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.strategies.ddp import DDPStrategy\n",
    "\n",
    "# Set up callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "directory_path = os.path.join(\"./scripts/checkpoints\", timestamp)\n",
    "\n",
    "csv_logger = CSVLogger(\"logs\", name=name + \"_logs\", version=timestamp)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=directory_path,\n",
    "    filename=name + \"_{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    every_n_epochs=train_kwargs.max_epochs,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "# Determine logging rate\n",
    "total_steps_per_epoch = len(train_dataloader)\n",
    "# Number of times to update logs per epoch (needs to be adjusted if sample size is small and batch size is big)\n",
    "num_log_updates_per_epoch = 4\n",
    "\n",
    "log_every_n_steps = total_steps_per_epoch // num_log_updates_per_epoch\n",
    "\n",
    "# Automatically log learning rate\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "callbacks = [checkpoint_callback, lr_monitor]\n",
    "\n",
    "trainer_args = Namespace(**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    del train_dataloader, val_dataloader\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        trainer_args,\n",
    "        logger=csv_logger,\n",
    "        callbacks=callbacks,\n",
    "        strategy=\"ddp_fork\",\n",
    "        accelerator=\"cuda\",\n",
    "        num_nodes=1,\n",
    "        devices=[0],\n",
    "        log_every_n_steps=log_every_n_steps,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    trainer.test(model, dataloaders=test_dataloader)\n",
    "else:\n",
    "    del test_dataloader\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        trainer_args,\n",
    "        logger=csv_logger,\n",
    "        callbacks=callbacks,\n",
    "        strategy=\"ddp_fork\",\n",
    "        accelerator=\"cuda\",\n",
    "        num_nodes=nodes,\n",
    "        devices=gpus,\n",
    "        log_every_n_steps=log_every_n_steps,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
